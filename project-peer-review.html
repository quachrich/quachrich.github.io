<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI in Peer Review — Harvard MJ Lab — Richard Quach</title>
    <link rel="stylesheet" href="project-style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@400;600&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="main-nav">
        <div class="nav-content">
            <a href="index.html" class="back-link">← Back</a>
            <a href="index.html" class="logo">RQ</a>
        </div>
    </nav>

    <main>
        <section class="project-hero">
            <div class="container">
                <div class="project-meta">
                    <span class="tag">AI & Academic Research</span>
                    <span class="timeline">December 2024 — May 2025</span>
                </div>
                <h1>AI in Peer Review: Error Detection and Academic Writing Support</h1>
                <p class="project-subtitle">
                    Undergraduate research at Harvard Medical School's MJ Lab examining how large language models can
                    support PhD paper review, detect errors in published literature, and enhance academic writing quality.
                </p>
            </div>
        </section>

        <section class="project-content">
            <div class="container-narrow">

                <div class="content-section">
                    <h2>Overview</h2>
                    <p>
                        At Harvard Medical School's MJ Lab (Data and Systems Science in Public Health), I contributed to
                        research investigating the role of AI — specifically ChatGPT — in academic peer review workflows.
                        The work spanned two connected lines of inquiry: evaluating how LLMs can assist with PhD-level
                        paper review, and developing a standardized process for using AI to detect errors in published
                        and retracted peer-reviewed papers.
                    </p>
                    <p>
                        The research sits at the intersection of AI capability evaluation and academic integrity, asking
                        how reliably and efficiently LLMs can flag methodological, statistical, and factual errors in
                        scientific literature — and what that means for the future of scientific quality control.
                    </p>
                </div>

                <div class="content-section">
                    <h2>Project Facts</h2>
                    <ul class="project-facts">
                        <li><strong>Institution:</strong> Harvard Medical School — MJ Lab, Data and Systems Science in Public Health</li>
                        <li><strong>Role:</strong> Undergraduate Researcher</li>
                        <li><strong>Focus:</strong> LLM-assisted peer review, error detection in published literature, grant research</li>
                        <li><strong>Context:</strong> ABCD study topics, retracted paper analysis, academic writing support</li>
                    </ul>
                    <p class="fineprint">
                        Note: This page describes my contributions as an undergraduate researcher. Study design, principal
                        investigation, and official outputs are managed by the MJ Lab and its faculty leadership.
                    </p>
                </div>

                <div class="content-section">
                    <h2>My Role</h2>
                    <ul class="project-list">
                        <li>
                            <strong>Literature review:</strong> Analyzed 50+ existing studies on the effectiveness of ChatGPT
                            in supporting PhD paper reviews, evaluating AI's role in enhancing academic writing quality,
                            streamlining feedback processes, and identifying open areas for further exploration.
                        </li>
                        <li>
                            <strong>Error detection project:</strong> Spearheaded a project leveraging ChatGPT to detect 50+ errors
                            in peer-reviewed papers, contributing to ongoing research on AI's capacity to surface methodological
                            and factual issues that human reviewers may miss.
                        </li>
                        <li>
                            <strong>Grant preparation:</strong> Assisted in drafting, preparing, and researching grant proposal
                            topics related to ABCD (Adolescent Brain Cognitive Development) study themes.
                        </li>
                        <li>
                            <strong>Standardized error-detection process:</strong> Developed and tested a repeatable workflow for
                            identifying errors in retracted papers — experimenting across different models, prompts, and settings
                            to maximize efficiency while maintaining accuracy.
                        </li>
                    </ul>
                </div>

                <div class="content-section">
                    <h2>The Research Question</h2>
                    <p>
                        Academic peer review is slow, inconsistent, and under-resourced. At the same time, LLMs have
                        demonstrated surprising capability at identifying logical gaps, inconsistent statistics, and
                        unsupported claims in scientific text. The MJ Lab's work asks: can AI-assisted review be
                        standardized well enough to be trustworthy and scalable?
                    </p>
                    <p>
                        My contribution focused on the empirical side of that question — testing what models can and
                        can't catch, how prompt design affects detection accuracy, and what a reproducible workflow
                        might look like in practice.
                    </p>
                </div>

                <div class="content-section">
                    <h2>Technical Approach</h2>
                    <ul class="project-list">
                        <li><strong>Model testing:</strong> Compared performance across different LLM configurations and prompt strategies for error detection tasks.</li>
                        <li><strong>Prompt engineering:</strong> Systematically varied prompt structure, specificity, and framing to evaluate impact on error-detection recall and precision.</li>
                        <li><strong>Ground truth:</strong> Used retracted papers with documented errors as a testbed, enabling objective evaluation of model outputs.</li>
                        <li><strong>Process documentation:</strong> Built a replicable workflow so the error-detection approach could be applied consistently across different papers and reviewers.</li>
                    </ul>
                </div>

                <div class="content-section">
                    <h2>Skills Developed</h2>
                    <ul class="project-list">
                        <li><strong>LLM evaluation:</strong> Designing structured tests to assess model performance on domain-specific tasks.</li>
                        <li><strong>Prompt engineering:</strong> Iterating on prompt design to maximize reliability and accuracy of AI outputs.</li>
                        <li><strong>Scientific literature review:</strong> Synthesizing 50+ studies into a coherent evidence base.</li>
                        <li><strong>Grant research and writing:</strong> Contributing to proposal development in an academic medical research environment.</li>
                        <li><strong>Research process design:</strong> Building standardized, repeatable workflows for AI-assisted research tasks.</li>
                    </ul>
                </div>

                <div class="stats-grid">
                    <div class="stat-item">
                        <div class="stat-number">50+</div>
                        <div class="stat-label">Studies Reviewed on AI in Peer Review</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">50+</div>
                        <div class="stat-label">Errors Detected in Published Papers</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">Harvard MS</div>
                        <div class="stat-label">MJ Lab, Data &amp; Systems Science</div>
                    </div>
                </div>

                <div class="content-section" style="margin-top: 3rem; padding-top: 2rem; border-top: 1px solid rgba(248, 244, 241, 0.2);">
                    <p style="font-size: 0.9rem; color: var(--text-light); font-style: italic;">
                        Note: This portfolio entry describes my contributions as an undergraduate researcher at the Harvard Medical School MJ Lab.
                        Research leadership, official outputs, and any publications are managed by the lab's principal investigators.
                    </p>
                </div>

            </div>
        </section>

        <section class="project-nav">
            <div class="container">
                <a href="index.html" class="next-project">
                    <span class="next-label">Back to Portfolio</span>
                    <h3>View All Projects →</h3>
                </a>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>© 2025 Richard Quach</p>
        </div>
    </footer>
</body>
</html>